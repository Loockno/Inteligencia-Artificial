import pandas as pd
import ollama
import random
import os
import time
from datetime import datetime, timedelta

# ================= CONFIGURACI√ìN =================
# Rotar entre modelos para mayor diversidad
MODELOS_DISPONIBLES = [
    "llama3.2:latest",  # Mejor calidad
    "mistral:7b",       # Excelente para creatividad
]

ARCHIVO_ENTRADA = 'dataset_proyecto3.csv'
ARCHIVO_SALIDA = 'dataset_aumentado_ollama.csv'

# Ajusta seg√∫n tu capacidad de procesamiento
CANTIDAD_A_GENERAR = 4500
MAX_REINTENTOS = 3  # Intentos por tweet si falla validaci√≥n

# Rangos realistas de engagement seg√∫n sentimiento
ENGAGEMENT_RANGES = {
    'positivo': {'likes': (1500, 8000), 'reposts': (200, 1500)},
    'neutral': {'likes': (1000, 5000), 'reposts': (150, 800)},
    'negativo': {'likes': (800, 4000), 'reposts': (100, 600)}
}
# =================================================

print("ü¶ô Generador de Dataset Mejorado para An√°lisis Gen Z")
print(f"üìä Modelos disponibles: {', '.join(MODELOS_DISPONIBLES)}\n")

# ========== FUNCIONES AUXILIARES ==========

def cargar_dataset_origen(archivo):
    """Carga el dataset con m√∫ltiples encodings"""
    for encoding in ['latin1', 'utf-8', 'cp1252', 'iso-8859-1']:
        try:
            df = pd.read_csv(archivo, encoding=encoding)
            print(f"‚úÖ Dataset cargado ({len(df)} registros) - Encoding: {encoding}")
            return df
        except:
            continue
    raise Exception("‚ùå No se pudo cargar el archivo con ning√∫n encoding")

def validar_tweet(texto):
    """Valida que el tweet cumpla criterios de calidad"""
    if not texto or len(texto.strip()) < 20:
        return False, "Muy corto"
    
    if len(texto) > 280:
        return False, "Excede 280 caracteres"
    
    # Detectar respuestas del modelo que no son tweets
    frases_prohibidas = [
        "claro", "aqu√≠ tienes", "por supuesto", "tweet:", 
        "aqu√≠ est√°", "este es", "ejemplo:", "respuesta:"
    ]
    texto_lower = texto.lower()[:50]  # Solo revisar inicio
    for frase in frases_prohibidas:
        if frase in texto_lower:
            return False, f"Contiene '{frase}'"
    
    # Evitar tweets que son solo puntuaci√≥n o emojis
    if len(texto.replace(" ", "").replace(".", "").replace(",", "")) < 15:
        return False, "Muy poca sustancia"
    
    return True, "OK"

def limpiar_tweet(texto):
    """Limpia el texto generado por el modelo"""
    texto = texto.strip()
    
    # Remover comillas al inicio/final
    if texto.startswith('"') and texto.endswith('"'):
        texto = texto[1:-1]
    if texto.startswith("'") and texto.endswith("'"):
        texto = texto[1:-1]
    
    # Remover prefijos comunes
    prefijos = ["Tweet: ", "tweet: ", "TWEET: ", "Respuesta: "]
    for prefijo in prefijos:
        if texto.startswith(prefijo):
            texto = texto[len(prefijo):]
    
    return texto.strip()

def generar_fecha_realista():
    """Genera fechas distribuidas a lo largo de 2024"""
    fecha_inicio = datetime(2024, 1, 1)
    dias_aleatorios = random.randint(0, 365)
    fecha = fecha_inicio + timedelta(days=dias_aleatorios)
    return fecha.strftime('%d/%m/%Y')

def generar_engagement(sentimiento, base_value, tipo='likes'):
    """Genera m√©tricas de engagement realistas"""
    rango = ENGAGEMENT_RANGES.get(sentimiento, ENGAGEMENT_RANGES['neutral'])[tipo]
    
    # Usar base_value como referencia pero con variaci√≥n
    if base_value > 0:
        factor = random.uniform(0.7, 1.3)
        valor = int(base_value * factor)
    else:
        valor = random.randint(rango[0], rango[1])
    
    # Asegurar que est√© en rango realista
    return max(rango[0], min(rango[1], valor))

def generar_tweet_ollama(tema, sentimiento, ejemplo, modelo):
    """Genera un tweet usando Ollama con prompt mejorado"""
    
    # Mapeo de sentimientos a instrucciones espec√≠ficas
    tono_map = {
        'positivo': 'optimista pero realista, con algo de iron√≠a generacional',
        'negativo': 'cr√≠tico, desencantado, tal vez sarc√°stico o resignado',
        'neutral': 'reflexivo y observador, sin tomar partido claro'
    }
    
    # Ejemplos de estilo Gen Z
    estilos_genz = [
        "usa lenguaje casual, puedes tener alg√∫n typo ocasional",
        "escribe como si estuvieras pensando en voz alta",
        "puedes usar emojis si suman al mensaje (sin exagerar)",
        "s√© aut√©ntico, no corporativo ni forzado"
    ]
    
    prompt = f"""Eres un usuario an√≥nimo de Twitter de la Generaci√≥n Z (18-25 a√±os).

Escribe UN SOLO tweet aut√©ntico sobre: "{tema}"

Tono: {tono_map.get(sentimiento, 'neutral')}
Estilo: {random.choice(estilos_genz)}

Reglas:
- Entre 50-280 caracteres
- Lenguaje casual, directo
- Puede tener errores de tipeo ocasionales (pero legible)
- NO uses m√°s de 2 emojis
- NO uses hashtags (o m√°ximo 1)
- Suena humano y real

Inspiraci√≥n (NO COPIES): "{ejemplo}"

IMPORTANTE: Responde SOLO con el texto del tweet. Sin introducciones ni explicaciones."""

    try:
        response = ollama.chat(
            model=modelo,
            messages=[{'role': 'user', 'content': prompt}],
            options={
                'temperature': 0.85,  # Balance creatividad/coherencia
                'top_p': 0.9,
                'top_k': 40,
                'num_predict': 100   # Limitar longitud de respuesta
            }
        )
        
        texto = response['message']['content']
        return limpiar_tweet(texto)
        
    except Exception as e:
        print(f"      ‚ùå Error con modelo {modelo}: {str(e)[:60]}")
        return None

def calcular_estadisticas(df):
    """Calcula estad√≠sticas del dataset generado"""
    stats = {
        'total': len(df),
        'promedio_longitud': df['texto'].str.len().mean(),
        'con_emoji': df['texto'].str.contains('[üòÄ-üôè]', regex=True).sum(),
        'por_sentimiento': df['sentimiento'].value_counts().to_dict(),
        'engagement_promedio': {
            'likes': df['likes'].mean(),
            'reposts': df['reposts'].mean()
        }
    }
    return stats

# ========== INICIALIZACI√ìN ==========

df_origen = cargar_dataset_origen(ARCHIVO_ENTRADA)

# Gestionar IDs para continuar donde nos quedamos
if os.path.exists(ARCHIVO_SALIDA):
    try:
        df_existente = pd.read_csv(ARCHIVO_SALIDA, usecols=['id'])
        max_orig = df_origen['id'].max()
        max_exist = df_existente['id'].max()
        ultimo_id = max(max_orig, int(max_exist)) if not pd.isna(max_exist) else max_orig
        print(f"‚û°Ô∏è  Continuando desde ID {ultimo_id + 1}\n")
    except:
        ultimo_id = df_origen['id'].max()
else:
    ultimo_id = df_origen['id'].max()
    print("üÜï Creando nuevo archivo de salida\n")

# ========== GENERACI√ìN PRINCIPAL ==========

nuevos_registros = []
estadisticas = {
    'generados': 0,
    'fallidos': 0,
    'reintentos_totales': 0
}

print(f"üöÄ Iniciando generaci√≥n de {CANTIDAD_A_GENERAR} tweets...\n")
start_time = time.time()

for i in range(CANTIDAD_A_GENERAR):
    # Seleccionar ejemplo padre aleatorio
    fila_padre = df_origen.sample(1).iloc[0]
    tema = fila_padre['tema']
    sentimiento = fila_padre['sentimiento']
    ejemplo = fila_padre['texto']
    
    id_actual = ultimo_id + 1 + i
    
    # Rotar entre modelos para diversidad
    modelo_actual = random.choice(MODELOS_DISPONIBLES)
    
    print(f"[{i+1}/{CANTIDAD_A_GENERAR}] ID:{id_actual} | Modelo: {modelo_actual}")
    print(f"   üìå Tema: {tema[:50]}...")
    print(f"   üí≠ Sentimiento: {sentimiento}")
    
    # Intentar generar con validaci√≥n
    tweet_valido = None
    for intento in range(MAX_REINTENTOS):
        tweet_generado = generar_tweet_ollama(tema, sentimiento, ejemplo, modelo_actual)
        
        if tweet_generado:
            es_valido, razon = validar_tweet(tweet_generado)
            
            if es_valido:
                tweet_valido = tweet_generado
                print(f"   ‚úÖ Generado ({len(tweet_generado)} chars)")
                break
            else:
                print(f"   ‚ö†Ô∏è  Intento {intento+1} rechazado: {razon}")
                estadisticas['reintentos_totales'] += 1
        else:
            print(f"   ‚ö†Ô∏è  Intento {intento+1} fall√≥ en generaci√≥n")
            estadisticas['reintentos_totales'] += 1
    
    if tweet_valido:
        # Crear registro completo
        nuevo_reg = {
            'id': id_actual,
            'fecha': generar_fecha_realista(),
            'texto': tweet_valido,
            'tema': tema,
            'sentimiento': sentimiento,
            'likes': generar_engagement(sentimiento, fila_padre['likes'], 'likes'),
            'reposts': generar_engagement(sentimiento, fila_padre['reposts'], 'reposts')
        }
        nuevos_registros.append(nuevo_reg)
        estadisticas['generados'] += 1
    else:
        print(f"   ‚ùå No se pudo generar despu√©s de {MAX_REINTENTOS} intentos")
        estadisticas['fallidos'] += 1
    
    print()  # L√≠nea en blanco
    
    # Guardado parcial cada 5 registros exitosos
    if len(nuevos_registros) >= 5:
        df_temp = pd.DataFrame(nuevos_registros)
        escribir_header = not os.path.exists(ARCHIVO_SALIDA)
        df_temp.to_csv(ARCHIVO_SALIDA, mode='a', header=escribir_header, 
                       index=False, encoding='utf-8-sig')
        print(f"üíæ Guardado parcial: {len(nuevos_registros)} registros\n")
        nuevos_registros = []

# Guardado final
if nuevos_registros:
    df_temp = pd.DataFrame(nuevos_registros)
    escribir_header = not os.path.exists(ARCHIVO_SALIDA)
    df_temp.to_csv(ARCHIVO_SALIDA, mode='a', header=escribir_header, 
                   index=False, encoding='utf-8-sig')
    print(f"üíæ Guardado final: {len(nuevos_registros)} registros")

# ========== REPORTE FINAL ==========

tiempo_total = time.time() - start_time
tiempo_promedio = tiempo_total / CANTIDAD_A_GENERAR if CANTIDAD_A_GENERAR > 0 else 0

print("\n" + "="*60)
print("‚ú® GENERACI√ìN COMPLETADA")
print("="*60)
print(f"‚è±Ô∏è  Tiempo total: {tiempo_total:.2f}s ({tiempo_promedio:.2f}s por tweet)")
print(f"‚úÖ Generados exitosos: {estadisticas['generados']}")
print(f"‚ùå Fallidos: {estadisticas['fallidos']}")
print(f"üîÑ Reintentos necesarios: {estadisticas['reintentos_totales']}")
print(f"üìà Tasa de √©xito: {(estadisticas['generados']/CANTIDAD_A_GENERAR*100):.1f}%")

# Estad√≠sticas del dataset completo
if os.path.exists(ARCHIVO_SALIDA):
    df_final = pd.read_csv(ARCHIVO_SALIDA)
    stats = calcular_estadisticas(df_final)
    
    print(f"\nüìä ESTAD√çSTICAS DEL DATASET COMPLETO:")
    print(f"   Total de registros: {stats['total']}")
    print(f"   Longitud promedio: {stats['promedio_longitud']:.0f} caracteres")
    print(f"   Tweets con emoji: {stats['con_emoji']} ({stats['con_emoji']/stats['total']*100:.1f}%)")
    print(f"   \n   Distribuci√≥n por sentimiento:")
    for sent, count in stats['por_sentimiento'].items():
        print(f"      ‚Ä¢ {sent}: {count} ({count/stats['total']*100:.1f}%)")
    print(f"   \n   Engagement promedio:")
    print(f"      ‚Ä¢ Likes: {stats['engagement_promedio']['likes']:.0f}")
    print(f"      ‚Ä¢ Reposts: {stats['engagement_promedio']['reposts']:.0f}")

print(f"\nüìÇ Archivo generado: {ARCHIVO_SALIDA}")
print("="*60)