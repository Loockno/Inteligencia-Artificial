import os
import glob
import feedparser
from langchain_community.document_loaders import CSVLoader
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_chroma import Chroma
from langchain_community.chat_models import ChatOllama
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough
from langchain_core.documents import Document

# --- CONFIGURACI√ìN ---
CSV_PATH = "./dataset_proyecto3.csv" 
RSS_FOLDER = "./rss_datos" 
MODEL_NAME = "mistral:7b"
OUTPUT_FILE = "reporte_final_generado.md" # Aqu√≠ se guardar√°n las respuestas

print(f"--- Sistema RAG Automatizado (Proyecto 3) con {MODEL_NAME} ---")

# --- LISTA COMPLETA DE PREGUNTAS DEL PROYECTO ---
PREGUNTAS_PROYECTO = [
    "¬øQu√© expresiones o t√©rminos utiliza la Gen Z para describir el vac√≠o existencial en redes sociales?",
    "¬øC√≥mo influyen los algoritmos de recomendaci√≥n en la construcci√≥n de su identidad?",
    "¬øQu√© emociones aparecen con mayor frecuencia cuando se habla de burnout o presi√≥n digital?",
    "¬øLa Gen Z percibe la autonom√≠a como algo propio o como algo condicionado por la tecnolog√≠a?",
    "¬øQu√© diferencias hay entre discursos aut√©nticos vs discursos performativos en plataformas como TikTok?",
    "¬øExisten patrones de lenguaje que indiquen crisis de sentido o desorientaci√≥n vital?",
    "¬øC√≥mo se refleja la idea de 'identidad l√≠quida' en los datos recuperados?",
    "¬øQu√© menciones aparecen sobre libertad, control o manipulaci√≥n algor√≠tmica?",
    "¬øSe observan se√±ales de que los algoritmos crean deseos o h√°bitos?",
    "¬øQu√© temas o preocupaciones predominan en la conversaci√≥n digital sobre prop√≥sito de vida?",
    "¬øHay evidencia de rechazo a los metarrelatos o valores tradicionales?",
    "¬øC√≥mo aparece la figura del 'yo digital' en los textos analizados?",
    "¬øQu√© ejemplos concretos muestran p√©rdida del pensamiento cr√≠tico por efecto de la burbuja de filtros?",
    "¬øExisten contrastes entre la visi√≥n que la Gen Z tiene de s√≠ misma y lo que los datos sugieren?",
    "¬øQu√© rol juega la hiperconectividad en la ansiedad o depresi√≥n mencionada?",
    "¬øSe observan patrones que apoyen las ideas de Byung-Chul Han sobre rendimiento y autoexplotaci√≥n?",
    "¬øC√≥mo interpretar√≠a Foucault el r√©gimen de vigilancia algor√≠tmica detectado?",
    "¬øQu√© evidencias hay de que la tecnolog√≠a 'desoculta' y transforma la vida seg√∫n Heidegger?",
    "¬øEl espacio p√∫blico digital est√° debilitado como afirma Habermas? ¬øQu√© muestran los datos?",
    "¬øCu√°les son los principales miedos, frustraciones y esperanzas de la Gen Z frente al futuro?"
]

# --- 1. CARGA DE DATOS (H√çBRIDA) ---
def load_data():
    docs = []
    
    # A) CSV
    print("1Ô∏è‚É£  Cargando Dataset CSV...")
    if os.path.exists(CSV_PATH):
        loader = CSVLoader(file_path=CSV_PATH, encoding="utf-8")
        csv_docs = loader.load()
        for doc in csv_docs:
            doc.page_content = f"[TESTIMONIO ESTUDIANTE] {doc.page_content}"
        docs.extend(csv_docs)
        print(f"   ‚úÖ {len(csv_docs)} registros sint√©ticos.")
    else:
        print(f"   ‚ùå No encontr√© {CSV_PATH}")

    # B) RSS
    print("2Ô∏è‚É£  Cargando Noticias RSS...")
    xml_files = glob.glob(os.path.join(RSS_FOLDER, "*.xml"))
    if xml_files:
        for file in xml_files:
            try:
                feed = feedparser.parse(file)
                for entry in feed.entries:
                    text = f"[NOTICIA REAL - Fuente: El Pa√≠s] {entry.title}. {entry.description}"
                    docs.append(Document(page_content=text, metadata={"source": "RSS"}))
                print(f"   ‚úÖ Le√≠do: {os.path.basename(file)}")
            except:
                pass
    else:
        print("   ‚ö†Ô∏è No hay archivos XML en rss_datos.")
    
    return docs

docs_totales = load_data()

# --- 2. VECTOR STORE ---
print("\nüß† Generando Embeddings (esto solo tarda la primera vez)...")
embedding_function = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")
vectorstore = Chroma.from_documents(docs_totales, embedding_function, persist_directory="./chroma_db_final")

# --- 3. CONFIGURACI√ìN RAG ---
llm = ChatOllama(model=MODEL_NAME, temperature=0.3)

template = """
Eres un fil√≥sofo experto analizando datos para el Proyecto: 'La Generaci√≥n Z y la Crisis de Sentido'.
Usa los siguientes datos recuperados para responder.

CONTEXTO:
{context}

PREGUNTA: 
{question}

INSTRUCCIONES:
1. Responde bas√°ndote estrictamente en el contexto (Testimonios y Noticias).
2. Cita autores cuando corresponda:
   - Cansancio/Rendimiento -> Byung-Chul Han.
   - Liquidez/Cambio -> Bauman.
   - Vigilancia/Poder -> Foucault.
   - Tecnolog√≠a/Ser -> Heidegger.
   - Espacio P√∫blico -> Habermas.
3. S√© directo y acad√©mico.

RESPUESTA:
"""
prompt = ChatPromptTemplate.from_template(template)
retriever = vectorstore.as_retriever(search_kwargs={"k": 7}) # Top 7 fragmentos m√°s relevantes

rag_chain = (
    {"context": retriever | (lambda docs: "\n\n".join(d.page_content for d in docs)), "question": RunnablePassthrough()}
    | prompt
    | llm
    | StrOutputParser()
)

# --- 4. EJECUCI√ìN Y GUARDADO ---
print(f"\nüöÄ Iniciando an√°lisis de las {len(PREGUNTAS_PROYECTO)} preguntas...")
print(f"üìù Los resultados se guardar√°n en: {OUTPUT_FILE}\n")

with open(OUTPUT_FILE, "w", encoding="utf-8") as f:
    f.write("# REPORTE DE AN√ÅLISIS AUTOMATIZADO CON RAG\n")
    f.write("## Proyecto 3: La Generaci√≥n Z y la Crisis de Sentido\n\n")

    for i, pregunta in enumerate(PREGUNTAS_PROYECTO, 1):
        print(f"‚è≥ ({i}/{len(PREGUNTAS_PROYECTO)}) Analizando: {pregunta[:40]}...")
        
        try:
            respuesta = rag_chain.invoke(pregunta)
            
            # Escribir en el archivo
            f.write(f"### Pregunta {i}: {pregunta}\n\n")
            f.write(f"**An√°lisis del Modelo:**\n\n{respuesta}\n\n")
            f.write("---\n\n")
            
            # Forzar guardado en disco por si se cancela el script
            f.flush() 
            
        except Exception as e:
            print(f"‚ùå Error en pregunta {i}: {e}")
            f.write(f"### Pregunta {i}: {pregunta}\n\nERROR: {e}\n\n---\n")

print(f"\n‚úÖ ¬°LISTO! Abre el archivo '{OUTPUT_FILE}' para ver tu reporte completo.")